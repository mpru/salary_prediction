---
title: "Data partitions"
format:
    html:
        embed-resources: true
code-fold: false
---

## Summary

::: {.callout-tip}
## Goal

The goal of this script is to split the available dataset into a training set (for fitting predictive models) and a test set (for validating them and calculating performance metrics).

:::

::: {.callout-note}
## Remarks

- Due to the small size of the dataset, a two-partition approach (train and test) will be used. Other approaches with more partitions (e.g., train, validation, and test) could be considered, as they may offer advantages in producing unbiased estimates of test error.  
- It is important to ensure that the randomness in creating the partitions does not lead to differing distributions of the response variable between train and test. Therefore, the partitions will be created by stratifying based on the **salary** variable, using percentiles.  
- All models to be fitted will use the same partitions.  
- An 80/20 split was chosen, reserving 80% for train and 20% for test.
:::

## Libraries and modules

```{python}
import pandas as pd
from sklearn.model_selection import train_test_split
```

## Create partitions

```{python}
# Load data
datos = pd.read_csv('../data/clean_data.csv')

# usar percentiles para respetar la distribucion de salary en ambos sets
intervalos = pd.qcut(x = datos['salary'], q = 5, labels = False, duplicates = 'drop')

# Split
train, test = train_test_split(datos, test_size = 0.2, random_state = 89, stratify = intervalos)

# Save
train.to_csv('../data/train_set.csv', index = False)
test.to_csv('../data/test_set.csv', index = False)
```

## Checking similar distribution for salary

```{python}
train['salary'].describe()
```

```{python}
test['salary'].describe()
```